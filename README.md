# ğŸ§  NeuroVision-HybridSwinCNN  
### Hybrid Swin Transformer + CNN for Brain Tumor MRI Classification

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.x-red)
![License](https://img.shields.io/badge/License-MIT-green)
![GUI](https://img.shields.io/badge/Interface-PyQt5-orange)

---

## ğŸ§© Overview

**NeuroVision-HybridSwinCNN** is a deep learningâ€“powered diagnostic system that combines the **Swin V2-Large Transformer** with a **custom CNN** for accurate brain tumor classification from MRI scans.  
The model achieves a **97% test accuracy**, outperforming traditional CNNs by leveraging both **global attention** (from Swin Transformer) and **local feature extraction** (from CNN).  

A modern **PyQt5 GUI** is included for real-time inference through simple **drag-and-drop** MRI analysis.

---

## âš™ï¸ Key Features
- ğŸ§  **Hybrid Swin V2-Large + CNN** architecture for precise tumor detection.  
- ğŸ“ˆ **97% test accuracy** after just 7 epochs of training.  
- ğŸ¯ Classifies four MRI categories: *Glioma, Meningioma, Pituitary, No Tumor*.  
- ğŸ§© **PyTorch-based** modular implementation.  
- ğŸ’» **PyQt5 GUI** with drag-and-drop functionality for end users.  
- âš¡ Validates MRI scans using strict multi-stage filtering (shape, texture, edges).  
- ğŸ” Provides class probability and confidence score.

---

## ğŸ§  Model Summary

| Metric | Description |
|:--|:--|
| **Model Type** | Hybrid Swin V2-Large + CNN |
| **Image Size** | 192 Ã— 192 |
| **Classes** | Glioma, Meningioma, Pituitary, No Tumor |
| **Training Data** | 5,712 MRI Images |
| **Testing Data** | 1,300 MRI Images |
| **Training Accuracy** | ~93.1% |
| **Testing Accuracy** | ~97.02% |
| **Optimizer** | AdamW (lr=1e-4, weight_decay=1e-5) |
| **Loss Function** | CrossEntropyLoss |
| **Epochs** | 7 (best model checkpoint) |

---

## ğŸ“Š Dataset Information

Dataset Used:  
ğŸ”— [Kaggle - Brain Tumor MRI Dataset](https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset)

This dataset contains **T1-weighted contrast-enhanced MRI** images categorized into:
- Glioma  
- Meningioma  
- Pituitary Tumor  
- No Tumor  

Ensure your dataset is structured as shown in the **folder structure** section before training.

---

## ğŸ“ Folder Structure
```
NeuroVision-HybridSwinCNN/
â”‚
â”œâ”€â”€ main.py 
â”œâ”€â”€ interface.py 
â”‚
â”œâ”€â”€ requirements.txt 
â”œâ”€â”€ README.md 
â”œâ”€â”€ README_RUN_FIRST.txt 
â”œâ”€â”€ .gitignore 
â”‚
â”œâ”€â”€ dataset/ # Dataset directory (not included in repo)
â”‚ â”œâ”€â”€ Training/
â”‚ â”‚ â”œâ”€â”€ glioma/
â”‚ â”‚ â”œâ”€â”€ meningioma/
â”‚ â”‚ â”œâ”€â”€ pituitary/
â”‚ â”‚ â””â”€â”€ notumor/
â”‚ â””â”€â”€ Testing/
â”‚ â”œâ”€â”€ glioma/
â”‚ â”œâ”€â”€ meningioma/
â”‚ â”œâ”€â”€ pituitary/
â”‚ â””â”€â”€ notumor/
â”‚
â””â”€â”€ model/ 
â””â”€â”€ model_epoch_7.pth

```
---

## âš™ï¸ Installation

### ğŸ§© Step 1 â€” Clone the Repository
```
git clone https://github.com/djoel-22/Hybrid-SwinV2-TransformerCNN-BrainTumorDetection.git
cd Hybrid-SwinV2-TransformerCNN-BrainTumorDetection
```
### ğŸ§© Step 2 â€” Create a Virtual Environment 
```
python -m venv venv
venv\Scripts\activate      # For Windows
source venv/bin/activate   # For macOS/Linux
```
### ğŸ§© Step 3 â€” Install Dependencies
```
pip install -r requirements.txt
```
### ğŸ§© Step 4 â€” Prepare Dataset
Download the dataset from the link above and place it


---

## ğŸ§¬ Training the Model

To train the **Hybrid Swin Transformer + CNN** model from scratch, simply run:


During training:
- The model will load images from the dataset folder.
- The Swin Transformer and CNN branches will extract global and local features.
- Checkpoints will be saved automatically in the `model/` directory after each epoch.

After training completes, the best checkpoint file will be saved as:
model/model_epoch_7.pth


---

## ğŸ’» Running the GUI Application

Once the model is trained (or you have the provided `.pth` file), run the following command to launch the **PyQt5 interface**:


Then:
1. Wait for the interface window to load.  
2. **Drag & Drop** an MRI image into the window or click to browse manually.  
3. The model will:
   - Validate the uploaded image (format, dimensions, and MRI-like texture).  
   - Run inference using the trained Hybrid model.  
   - Display the **Predicted Tumor Type** and **Confidence Score** on-screen.  

Alternatively, if you have the **EXE version**, simply double-click the application file and wait a few seconds for it to load â€” no setup required.

---

## ğŸ§¾ Example Prediction Output

| MRI Image | Predicted Class | Confidence |
|:--:|:--:|:--:|
| <img src="lib/800wm.jpg" width="220"> | **Glioma** | 96.4% |
| <img src="lib/unnamed.jpg" width="220"> | **Meningioma** | 93.8% |

---

## ğŸ§  Model Architecture Overview
```
Input Image (192x192 RGB)
â”‚
â–¼
Swin V2-Large Transformer â†’ Global Attention Features
â”‚
â–¼
Custom CNN Branch â†’ Local Spatial Features
â”‚
â–¼
Concatenation Layer â†’ Combine Global + Local
â”‚
â–¼
Fully Connected Layers â†’ Classification (4 Tumor Types)
```

---

## âš™ï¸ Technologies Used

| Category | Tools |
|:--|:--|
| **Programming Language** | Python 3.10+ |
| **Deep Learning Framework** | PyTorch |
| **Transformer Backbone** | Swin V2-Large (from timm) |
| **GUI Framework** | PyQt5 |
| **Image Processing** | OpenCV, PIL |
| **Training Utility** | tqdm |
| **Deployment (optional)** | PyInstaller / cx_Freeze |


## ğŸ“ˆ Results Summary

| Metric | Value |
|:--|:--|
| **Training Accuracy** | ~93.1% |
| **Testing Accuracy** | ~97.02% |
| **Loss Function** | CrossEntropyLoss |
| **Optimizer** | AdamW |
| **Learning Rate** | 1e-4 |
| **Epochs** | 7 |
| **Best Model** | model/model_epoch_7.pth |

---

## âš ï¸ Important Note Before Running

> âš ï¸ **Read Carefully Before Running the Application**
>
> - You **donâ€™t need to configure anything** â€” just double-click the `.exe` file (or run `interface.py`).
> - Wait a few seconds for the GUI to load.
> - Drag and drop an MRI image into the window.
> - The model will automatically validate and predict the tumor type in seconds.

---

## ğŸ§¾ Model Performance Summary

| Class | Accuracy (%) |
|:--|:--|
| Glioma | 96.8 |
| Meningioma | 97.2 |
| Pituitary | 97.5 |
| No Tumor | 98.1 |

Overall **Test Accuracy: 97.02%**

---

## ğŸ‘¥ Authors

| Contributors | Contribution |
|:--|:--|
| **R Jerome FelixRaj**, **D Joel Gunaseelan** | Model Architecture, Training & Integration, GUI Design, Application Development & Testing |


---

## â­ Acknowledgements

- Dataset courtesy of **Masoud Nickparvar** â€” [Brain Tumor MRI Dataset (Kaggle)](https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset)  
- **Swin Transformer V2** by Microsoft Research Asia (2022).  
- Special thanks to open-source contributors in the AI medical imaging community.




